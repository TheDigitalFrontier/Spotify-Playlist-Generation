{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Milestone 3 notebook is comprised of three sections:\n",
    "\n",
    "### 1) Data joining with Pandas\n",
    "### 2) Data enrichment with Spotipy from Spotify Web API\n",
    "### 3) Data visualization with seaborn\n",
    "\n",
    "--------------------------------------------------------------------------\n",
    "***Note: We do not recommend running this notebook as all in all, it will take about 13-14 hours to complete. We ran it in its three separate components over a period of days to finalize.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "sns.set()\n",
    "\n",
    "\n",
    "\n",
    "from itertools import chain\n",
    "\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials \n",
    "\n",
    "client_id = \"9c828632c4884d67b66fdd35545b7ba8\"\n",
    "client_secret = \"d846b33b9b154046ba46a27e3f8f684b\"\n",
    "\n",
    "client_credentials_manager = SpotifyClientCredentials(client_id=client_id, client_secret=client_secret)\n",
    "sp = spotipy.Spotify(client_credentials_manager=client_credentials_manager)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Data joining with Pandas\n",
    "\n",
    "### Spot check an individual songs file to explore its format and data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/Songs/songs285.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "list(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a lot of data: ball-park 65,000 rows in 1,000 files, totaling around 65,000,000 observations â€“ or songs in playlists, many of which are certainly repeated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some very different playlist lengths\n",
    "df.groupby('pid')['track_uri'].nunique()[10:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = listdir('../data/Songs')\n",
    "print(len(all_files))\n",
    "all_files[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structuring the data\n",
    "A reasonable first step to slim down the size of the dataset without losing information or fidelity, is to parse through all the files to create a reference table/file of all songs and their metadata. Each playlist can then be stored as a simple named object, where the name is the overall playlist id and its value a vector of song ids.\n",
    "\n",
    "### Looping over all our files to fill out the master DataFrame (songs) and Series (playlists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "loop_start = time.time()\n",
    "\n",
    "# List of all files\n",
    "all_files = listdir('../data/Songs')\n",
    "# Ditch half the playlists; 500,000 playlists is plenty\n",
    "all_files = all_files[0:200]\n",
    "\n",
    "# Load first file to get columns (standard across all)\n",
    "df = pd.read_csv('../data/Songs/' + all_files[0])\n",
    "\n",
    "# Master DataFrame of all unique songs included across all playlists\n",
    "#songs = pd.DataFrame(columns = list(df.columns)[2:])\n",
    "songs = pd.DataFrame()\n",
    "\n",
    "# Master Series of playlists and the songs included in each\n",
    "playlists = pd.Series()\n",
    "\n",
    "# Aggregator functions to limit to one row per song and count occurrences across playlists\n",
    "a1 = dict()\n",
    "for key in df.columns[2:]:\n",
    "    a1[key] = 'first'\n",
    "a1['track_uri'] = 'count'\n",
    "\n",
    "# Aggregator to consolidate into sum of songs across playlists\n",
    "a2= dict()\n",
    "for key in df.columns[2:]:\n",
    "    a2[key] = 'first'\n",
    "del a2['track_uri']\n",
    "a2['count'] = 'sum'\n",
    "\n",
    "# Loop over each file to extract data\n",
    "for i, file in enumerate(all_files):\n",
    "    # split on \".\" to split into \"filename\" and \"csv\"\n",
    "    # Then select \"filename\" and ditch the first five letters \"songs\"\n",
    "    filenum = file.split(\".\")[0][5:]\n",
    "    \n",
    "    # Load file and store in temporary dataframe\n",
    "    fdf = pd.read_csv('../data/Songs/' + file)\n",
    "    \n",
    "    # --- SONGS IN FILE ---\n",
    "    fdf_counts = fdf.iloc[:, 2:]\n",
    "    fdf_counts = fdf_counts.groupby('track_uri').agg(a1)\n",
    "    fdf_counts.rename(columns = {'track_uri': 'count'}, inplace = True)\n",
    "    \n",
    "    # Add to df of unique songs, update counters, and remove duplicates\n",
    "    songs = songs.append(fdf_counts)\n",
    "    \n",
    "    # -- SONGS IN EACH PLAYLIST --\n",
    "    # Songs included in every playlist (ordered) in file\n",
    "    # For each playlist, get list of track_uri's (unique identifiers)\n",
    "    songs_in_playlist = fdf.groupby('pid')['track_uri'].unique()\n",
    "\n",
    "    # Update index to be not the pid in file (id), but a combination of them\n",
    "    #songs_in_playlist.index = [filenum + '_' + str(pid) for pid in songs_in_playlist.index.values]\n",
    "    songs_in_playlist.index = list(map(lambda x: filenum + '_' + str(x), songs_in_playlist.index.values))\n",
    "    \n",
    "    # Add playlists to master Series of all playlists\n",
    "    playlists = playlists.append(songs_in_playlist)\n",
    "    \n",
    "    # Every 50 files, consolidate the songs table so it doesn't grow too big\n",
    "    if (i+1)%25 == 0: \n",
    "        print('{}/{} -- {} s'.format(i+1, len(all_files), time.time() - loop_start))\n",
    "        loop_start = time.time()\n",
    "        songs = songs.groupby('track_uri').agg(a2, sort = True)\n",
    "        print('   Consolidation: {} s'.format(time.time() - loop_start))\n",
    "    \n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do a final consolidation just to be safe (should be very fast)\n",
    "# Add song ID to table, now that it only contains unique songs\n",
    "start_time = time.time()\n",
    "songs_counts = songs.groupby('track_uri').agg(a2)\n",
    "songs_counts['song_id'] = np.arange(len(songs_counts))\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "print(songs_counts.shape)\n",
    "display(songs_counts.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace playlist track_uri with song_id\n",
    "start_time = time.time()\n",
    "loop_start = time.time()\n",
    "\n",
    "playlists_songids = pd.Series(index = playlists.index)\n",
    "playlists_songids = playlists_songids.astype(object)\n",
    "\n",
    "i = 0\n",
    "for ind, row in playlists.items():\n",
    "    songids = np.array(songs_counts.loc[row, 'song_id'], 'int')\n",
    "    playlists_songids.loc[str(ind)] = songids\n",
    "    \n",
    "    i += 1\n",
    "    if i % (len(playlists)/20) == 0 == 0: \n",
    "        print('{}/{} -- {} s'.format(i, int(len(playlists)), time.time() - loop_start))\n",
    "        loop_start = time.time()\n",
    "    \n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "print(playlists_songids.shape)\n",
    "print(playlists_songids.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change songs table to have song id as index and track_uri as column\n",
    "# We will be doing lookups on song_id while running\n",
    "songs_counts_id = songs_counts.copy()\n",
    "songs_counts_id['track_uri'] = songs_counts_id.index.values\n",
    "songs_counts_id.set_index('song_id', inplace = True)\n",
    "songs_counts_id.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write files to disk (csv and pickle)\n",
    "Use `pd.read_pickle` to easily read back in a data frame or series with the exact same structure as the one you dumped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs_counts_id.to_csv('../data/songs_counts_'+str(len(all_files))+'.csv')\n",
    "songs_counts_id.to_pickle('../data/songs_counts_'+str(len(all_files))+'.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlists_songids.to_csv('../data/playlists_song_ids_'+str(len(all_files))+'.csv', header = False)\n",
    "playlists_songids.to_pickle('../data/playlists_song_ids_'+str(len(all_files))+'.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Data enrichment with Spotipy from Spotify Web API\n",
    "\n",
    "\n",
    "### Ingest saved raw data\n",
    "\n",
    "This occurred asynchronously so was easier to export and ingest again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('../data/songs_counts_200.pkl')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enrich with new track features from Spotify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define batches\n",
    "batch_size = 100\n",
    "num_batches = math.ceil(len(df)/batch_size)\n",
    "\n",
    "# initialize list to save API calls\n",
    "track_features = []\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# looping through the batches\n",
    "for i in range(num_batches):\n",
    "    \n",
    "    \n",
    "    # define start and end of the batch\n",
    "    start_point = i*batch_size\n",
    "    end_point = min(start_point + batch_size, len(df))\n",
    "    \n",
    "    # API call\n",
    "    track_list = list(df['track_uri'][start_point:end_point])\n",
    "    track_features.extend(sp.audio_features(track_list))\n",
    "\n",
    "    if i%100 == 0:\n",
    "        print('{}/{}, {}s'.format(i, num_batches, time.time()-start_time))\n",
    "        start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_features_df = pd.DataFrame(track_features)\n",
    "track_features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_features_df.to_csv('../data/track_features'+str(counter)+'.csv')\n",
    "track_features_df.to_pickle('../data/track_features'+str(counter)+'.pkl')\n",
    "counter += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enrich with new artist features from Spotify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_artists = list(df['artist_uri'].unique())\n",
    "len(unique_artists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define batches\n",
    "batch_size = 50\n",
    "num_batches = math.ceil(len(unique_artists)/batch_size)\n",
    "\n",
    "# initialize list to save API calls\n",
    "artist_info = []\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# looping through the batches\n",
    "for i in range(num_batches):\n",
    "    \n",
    "    \n",
    "    # define start and end of the batch\n",
    "    start_point = i*batch_size\n",
    "    end_point = min(start_point + batch_size, len(df))\n",
    "    \n",
    "    # API call\n",
    "    artist_list = unique_artists[start_point:end_point]\n",
    "    artist_info.extend(sp.artists(artist_list)['artists'])\n",
    "\n",
    "    if i%100 == 0:\n",
    "        print('{}/{}, {}s'.format(i, num_batches, time.time()-start_time))\n",
    "        start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_info_df = pd.DataFrame(artist_info)\n",
    "artist_info_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(list(chain.from_iterable(artist_info_df['genres']))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_info_df.to_csv('../data/artist_info'+str(counter)+'.csv')\n",
    "artist_info_df.to_pickle('../data/artist_info'+str(counter)+'.pkl')\n",
    "counter += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enrich with new artist features from Spotify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_albums = list(df['album_uri'].unique())\n",
    "len(unique_albums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# albums_exist = pd.read_pickle('../data/album_info1.pkl')\n",
    "albums_exist = list(albums_exist['uri'])\n",
    "print(len(albums_exist))\n",
    "# albums_exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(unique_albums_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique_albums_new = [i for i in unique_albums if i not in albums_exist]\n",
    "unique_albums_new = list(set(unique_albums) - set(albums_exist))\n",
    "print(len(unique_albums_new))\n",
    "# unique_albums_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_albums = unique_albums_new[140000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(unique_albums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define batches\n",
    "batch_size = 20\n",
    "num_batches = math.ceil(len(unique_albums)/batch_size)\n",
    "\n",
    "# initialize list to save API calls\n",
    "album_info = []\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# looping through the batches\n",
    "for i in range(num_batches):\n",
    "    \n",
    "    \n",
    "    # define start and end of the batch\n",
    "    start_point = i*batch_size\n",
    "    end_point = min(start_point + batch_size, len(df))\n",
    "    \n",
    "    # API call\n",
    "    album_list = unique_albums[start_point:end_point]\n",
    "    album_info.extend(sp.albums(album_list)['albums'])\n",
    "\n",
    "    if i%100 == 0:\n",
    "        print('{}/{}, {}s'.format(i, num_batches, time.time()-start_time))\n",
    "        start_time = time.time()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminates None values\n",
    "album_info = [i for i in album_info if i is not None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "album_info_df = pd.DataFrame(album_info)\n",
    "album_info_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "album_info_df.to_csv('../data/album_info'+str(counter)+'.csv')\n",
    "album_info_df.to_pickle('../data/album_info'+str(counter)+'.pkl')\n",
    "counter += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join all gathered enriched data together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns just for albums for clarity\n",
    "album_columns = ['genres','popularity','release_date','uri']\n",
    "\n",
    "albums1 = pd.read_csv('../data/album_info1.csv', usecols=album_columns)\n",
    "albums2 = pd.read_csv('../data/album_info2.csv', usecols=album_columns)\n",
    "albums3 = pd.read_csv('../data/album_info3.csv', usecols=album_columns)\n",
    "albums4 = pd.read_csv('../data/album_info4.csv', usecols=album_columns)\n",
    "albums5 = pd.read_csv('../data/album_info5.csv', usecols=album_columns)\n",
    "albums6 = pd.read_csv('../data/album_info6.csv', usecols=album_columns)\n",
    "albums = pd.concat([albums1, albums2, albums3, albums4, albums5, albums6], axis=0, ignore_index=True)\n",
    "\n",
    "albums = albums.rename(columns={'genres': 'album_genres', 'popularity': 'album_popularity', 'release_date': 'album_release_date', 'uri': 'album_uri'})\n",
    "albums = albums.drop_duplicates()\n",
    "\n",
    "albums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns just for artists for clarity\n",
    "artist_columns = ['genres','popularity','uri']\n",
    "artists = pd.read_csv('../data/artist_info1.csv', usecols=artist_columns)\n",
    "\n",
    "artists = artists.rename(columns={'genres': 'artist_genres', 'popularity': 'artist_popularity', 'uri': 'artist_uri'})\n",
    "artists = artists.drop_duplicates()\n",
    "\n",
    "artists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns just for tracks for clarity\n",
    "track_columns = ['danceability','energy','key','loudness','mode','speechiness','acousticness','instrumentalness','liveness','valence','tempo','time_signature','uri']\n",
    "tracks = pd.read_csv('../data/track_features3.csv', usecols=track_columns)\n",
    "\n",
    "tracks = tracks.rename(columns={'uri': 'track_uri'})\n",
    "tracks = tracks.drop_duplicates()\n",
    "\n",
    "tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master = pd.read_pickle('../data/songs_counts_200.pkl')\n",
    "master['song_id'] = master.index\n",
    "master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master = master.merge(track_features, on='track_uri', suffixes=(None, '_tracks'))\n",
    "master = master.merge(artists, on='artist_uri', suffixes=(None, '_artists'))\n",
    "master = master.merge(albums, on='album_uri', suffixes=(None, '_albums'))\n",
    "master = master.set_index('song_id')\n",
    "master"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save final enriched dataset to master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master.to_csv('../data/master200.csv')\n",
    "master.to_pickle('../data/master200.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Data visualization with seaborn\n",
    "\n",
    "### Ingest saved raw data\n",
    "\n",
    "This occurred asynchronously so was easier to export and ingest again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs = pd.read_pickle('../../data/200_first_playlists/master200.pkl')\n",
    "playlists = pd.read_pickle('../../data/200_first_playlists/playlists_song_ids_200.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of song appearances across playlists\n",
    "plt.subplots(figsize=(10,5))\n",
    "plt.hist(songs.loc[(songs['count'] > 1) & (songs['count'] < 50), 'count'], bins = 30)\n",
    "plt.suptitle('Distribution of song appearances across playlists')\n",
    "plt.title('Filtered to 1 < frequency < 50 as there is an extremely long right tail');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of number of songs in playlist\n",
    "plt.subplots(figsize=(10,5))\n",
    "playlist_lengths = np.array([len(p) for p in playlists.values], 'int')\n",
    "plt.hist(playlist_lengths, bins = 50)\n",
    "plt.axvline(x=20, color=\"#1DB954\")\n",
    "plt.title('Distribution of number of songs in playlist', size=15);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chart a number of histograms related to track features\n",
    "start_time = time.time()\n",
    "fig, ax = plt.subplots(4,3, figsize=(20,10))\n",
    "columns = [\"duration_ms\", \"count\", \"danceability\", \"energy\", \"tempo\", \"loudness\",\n",
    "                \"speechiness\", \"acousticness\", \"instrumentalness\", \"liveness\",\n",
    "                \"artist_popularity\", \"album_popularity\"] #\"valence\", \"key\"\n",
    "col_iter = iter(columns)\n",
    "for row in range(4):\n",
    "    for col in range(3):\n",
    "        sns.distplot(songs[next(col_iter)], ax=ax[row,col])\n",
    "print('Time elapsed: {} seconds'.format(round(time.time()-start_time, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes about 20 minutes so only uncomment and run intentionally\n",
    "# Charts pairplot for all features against each other to identify colinear relationships\n",
    "start_time = time.time()\n",
    "to_plot = [\"duration_ms\", \"count\", \"danceability\", \"energy\", \"tempo\", \"loudness\",\n",
    "                \"speechiness\", \"acousticness\", \"instrumentalness\", \"liveness\",\n",
    "                \"artist_popularity\", \"album_popularity\"] #\"valence\", \"key\"\n",
    "df_to_plot = songs.loc[:,to_plot]\n",
    "# sns.pairplot(df_to_plot); # Uncomment this to generate pairplot\n",
    "plt.title(\"Pairplot for Song Features\")\n",
    "print('Time elapsed: {} seconds'.format(round(time.time()-start_time, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes about 10 minutes so only uncomment and run intentionally\n",
    "# Distribution plot of loudness vs energy\n",
    "start_time = time.time()\n",
    "# sns.jointplot(x=\"energy\", y=\"loudness\", data=songs, kind=\"kde\");\n",
    "print('Time elapsed: {} seconds'.format(round(time.time()-start_time, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes about 10 minutes so only uncomment and run intentionally\n",
    "# Distribution plot of danceability vs tempo\n",
    "start_time = time.time()\n",
    "# sns.jointplot(x=\"tempo\", y=\"danceability\", data=songs, kind=\"kde\");\n",
    "print('Time elapsed: {} seconds'.format(round(time.time()-start_time, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explores playlist inclusion by danceability\n",
    "start_time = time.time()\n",
    "plt.subplots(figsize=(10,10))\n",
    "sns.scatterplot(x=\"count\", y=\"danceability\", data=songs)\n",
    "plt.title(\"Playlist inclusion rate increases with danceability\", size=15)\n",
    "print('Time elapsed: {} seconds'.format(round(time.time()-start_time, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explores playlist inclusion by loudness\n",
    "start_time = time.time()\n",
    "plt.subplots(figsize=(10,10))\n",
    "sns.scatterplot(x=\"count\", y=\"loudness\", data=songs);\n",
    "plt.title(\"Loudness is important for inclusion up to a point\", size=15)\n",
    "print('Time elapsed: {} seconds'.format(round(time.time()-start_time, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explores playlist inclusion by artist popularity\n",
    "start_time = time.time()\n",
    "plt.subplots(figsize=(10,10))\n",
    "sns.scatterplot(x=\"count\", y=\"artist_popularity\", data=songs);\n",
    "plt.title(\"More popular artists are included in more playlists at an increasing rate\", size=15)\n",
    "print('Time elapsed: {} seconds'.format(round(time.time()-start_time, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explores playlist inclusion by energy\n",
    "start_time = time.time()\n",
    "plt.subplots(figsize=(10,10))\n",
    "sns.scatterplot(x=\"count\", y=\"energy\", data=songs);\n",
    "plt.title(\"Energy has little to no impact on inclusion\", size=15)\n",
    "print('Time elapsed: {} seconds'.format(round(time.time()-start_time, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explores playlist inclusion by song duration\n",
    "start_time = time.time()\n",
    "plt.subplots(figsize=(10,10))\n",
    "sns.scatterplot(x=\"count\", y=\"duration_ms\", data=songs);\n",
    "# plt.axhline(y=350000, color=\"#1DB954\", linestyle='-')\n",
    "plt.title(\"Long songs are unlikely to be added to playlists\", size=15)\n",
    "print('Time elapsed: {} seconds'.format(round(time.time()-start_time, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explores danceability by tempo\n",
    "start_time = time.time()\n",
    "plt.subplots(figsize=(10,10))\n",
    "sns.scatterplot(x=\"tempo\", y=\"danceability\", data=songs); # The sweet spot of danceability\n",
    "plt.title(\"The Tempo Bump: tempos around 125 bpms have much higher danceability\", size=15)\n",
    "print('Time elapsed: {} seconds'.format(round(time.time()-start_time, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explores playlist inclusion by album popularity\n",
    "start_time = time.time()\n",
    "plt.subplots(figsize=(10,10))\n",
    "sns.scatterplot(x=\"count\", y=\"album_popularity\", data=songs);\n",
    "plt.title(\"Popular songs from unpopular albums (\\\"One Hit Wonders\\\") are still included in many playlists \", size=10)\n",
    "print('Time elapsed: {} seconds'.format(round(time.time()-start_time, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explores playlist inclusion by tempo excluding significant outliers\n",
    "# Highlights peak tempo points of notable popularity\n",
    "plt.subplots(figsize=(20,10))\n",
    "sns.distplot(songs[(songs.tempo > 30)&(songs.tempo < 230)].tempo, kde=False, bins=200)\n",
    "plt.axvline(x=80, color=\"#1DB954\", ls=\"--\")\n",
    "plt.axvline(x=100, color=\"#1DB954\")\n",
    "plt.axvline(x=120, color=\"#1DB954\")\n",
    "plt.axvline(x=128, color=\"#1DB954\")\n",
    "plt.axvline(x=139, color=\"#1DB954\")\n",
    "plt.axvline(x=170, color=\"#1DB954\")\n",
    "plt.title(\"Clear peaks in tempo popularity, suggesting preferred listener tempos\", size=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Derive new release_year column\n",
    "start_time = time.time()\n",
    "songs['release_year'] = songs.apply(lambda row: row['album_release_date'][0:4], axis=1)\n",
    "print(songs[0:5])\n",
    "print('Time elapsed: {} seconds'.format(round(time.time()-start_time, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to years with sufficient observations\n",
    "century_songs = songs[(songs.release_year.astype(int) > 1950) & (songs.release_year.astype(int) < 2017)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chart album_release_year distribution to understand when songs were made\n",
    "start_time = time.time()\n",
    "fig, ax = plt.subplots(figsize=(20,10))\n",
    "sns.countplot(x=\"release_year\", data=century_songs)\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=80)\n",
    "ax.set_title(\"Album Release Year Distribution on Spotify: 1950 - 2017\", size=25)\n",
    "print('Time elapsed: {} seconds'.format(round(time.time()-start_time, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale loudness and tempo to allow plotting on some chart as others\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler()\n",
    "century_songs['loudness_scaled'] = sc.fit_transform(np.array(century_songs['loudness']).reshape(-1,1))\n",
    "display(century_songs['loudness_scaled'][0:5])\n",
    "century_songs['tempo_scaled'] = sc.fit_transform(np.array(century_songs['tempo']).reshape(-1,1))\n",
    "display(century_songs['tempo_scaled'][0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chart all track features over time\n",
    "start_time = time.time()\n",
    "fig, ax = plt.subplots(figsize=(20,10))\n",
    "sns.lineplot(x=\"release_year\", y=\"danceability\", data=century_songs, label=\"danceability\")\n",
    "sns.lineplot(x=\"release_year\", y=\"energy\", data=century_songs, label=\"energy\")\n",
    "sns.lineplot(x=\"release_year\", y=\"liveness\", data=century_songs, label=\"liveness\")\n",
    "sns.lineplot(x=\"release_year\", y=\"speechiness\", data=century_songs, label=\"speechiness\")\n",
    "sns.lineplot(x=\"release_year\", y=\"acousticness\", data=century_songs, label=\"acousticness\")\n",
    "sns.lineplot(x=\"release_year\", y=\"instrumentalness\", data=century_songs, label=\"instrumentalness\")\n",
    "sns.lineplot(x=\"release_year\", y=\"valence\", data=century_songs, label=\"valence\") #, color=\"#1DB954\"\n",
    "sns.lineplot(x=\"release_year\", y=\"loudness_scaled\", data=century_songs, label=\"loudness\") #, color=\"#1DB954\"\n",
    "sns.lineplot(x=\"release_year\", y=\"tempo_scaled\", data=century_songs, label=\"tempo\") #, color=\"#1DB954\"\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=45)\n",
    "ax.set_title(\"Song Features Change Over Time: 1950 - 2017\", size=20);\n",
    "ax.set_ylabel(\"Feature level\")\n",
    "print('Time elapsed: {} seconds'.format(round(time.time()-start_time, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Focus on loudness changes over time\n",
    "start_time = time.time()\n",
    "fig, ax = plt.subplots(figsize=(20,10))\n",
    "sns.lineplot(x=\"release_year\", y=\"loudness_scaled\", data=century_songs, label=\"loudness\", color=\"#1DB954\")\n",
    "plt.axvline(x=40, color=\"red\")\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=45);\n",
    "ax.set_title(\"Song Loudness Change Over Time: 1950 - 2017\", size=20);\n",
    "print('Time elapsed: {} seconds'.format(round(time.time()-start_time, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Focus on danceability changes over time\n",
    "start_time = time.time()\n",
    "fig, ax = plt.subplots(figsize=(20,10))\n",
    "sns.lineplot(x=\"release_year\", y=\"danceability\", data=century_songs, label=\"danceability\", color=\"#1DB954\")\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=45);\n",
    "plt.axvline(x=60, color=\"red\")\n",
    "ax.set_title(\"Song Danceability Change Over Time: 1950 - 2017\", size=20);\n",
    "print('Time elapsed: {} seconds'.format(round(time.time()-start_time, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigate musical keys of most popular songs\n",
    "start_time = time.time()\n",
    "preferred_artists = songs[songs['count'] > 4050]\n",
    "print(len(songs), len(preferred_artists))\n",
    "plt.subplots(figsize=(10,10))\n",
    "sns.countplot(y=\"key\", data=preferred_artists);\n",
    "plt.title(\"Most popular key for Top 100 most included songs\", size=15)\n",
    "print('Time elapsed: {} seconds'.format(round(time.time()-start_time, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview of top playlist genres\n",
    "songs['artist_genres'].value_counts()[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates length of longest and shortest playlists\n",
    "playlist_lengths = [len(playlist) for playlist in playlists]\n",
    "print(\"Largest playlist\", max(playlist_lengths))\n",
    "print(\"Smallest playlist: \", min(playlist_lengths))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
