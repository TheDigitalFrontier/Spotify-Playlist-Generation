{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "import time\n",
    "\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load master song table with added metadata\n",
    "master = pd.read_pickle('../data/master200.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(999950, 25)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist_name</th>\n",
       "      <th>artist_uri</th>\n",
       "      <th>track_name</th>\n",
       "      <th>album_uri</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>album_name</th>\n",
       "      <th>count</th>\n",
       "      <th>track_uri</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>...</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>artist_genres</th>\n",
       "      <th>artist_popularity</th>\n",
       "      <th>album_genres</th>\n",
       "      <th>album_popularity</th>\n",
       "      <th>album_release_date</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>song_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sidney Bechet's Blue Note Jazzmen</td>\n",
       "      <td>spotify:artist:2XouUSO0EAJ9gMMoHiXqMt</td>\n",
       "      <td>Muskrat Ramble</td>\n",
       "      <td>spotify:album:04hQBJ7YSuNnZ0nbuXNYbY</td>\n",
       "      <td>220293</td>\n",
       "      <td>Jazz Classics</td>\n",
       "      <td>1</td>\n",
       "      <td>spotify:track:0002yNGLtYSYtc0X6ZnFvp</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.623</td>\n",
       "      <td>...</td>\n",
       "      <td>0.903</td>\n",
       "      <td>0.6340</td>\n",
       "      <td>0.951</td>\n",
       "      <td>182.345</td>\n",
       "      <td>4</td>\n",
       "      <td>[]</td>\n",
       "      <td>18</td>\n",
       "      <td>[]</td>\n",
       "      <td>37</td>\n",
       "      <td>1993-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159583</th>\n",
       "      <td>Sidney Bechet</td>\n",
       "      <td>spotify:artist:1RsmXc1ZqW3WBs9iwxiSwk</td>\n",
       "      <td>Blue Horizon</td>\n",
       "      <td>spotify:album:04hQBJ7YSuNnZ0nbuXNYbY</td>\n",
       "      <td>264933</td>\n",
       "      <td>Jazz Classics</td>\n",
       "      <td>5</td>\n",
       "      <td>spotify:track:1EWPMNHfdVNJwBpG9BcxXB</td>\n",
       "      <td>0.327</td>\n",
       "      <td>0.372</td>\n",
       "      <td>...</td>\n",
       "      <td>0.835</td>\n",
       "      <td>0.1530</td>\n",
       "      <td>0.380</td>\n",
       "      <td>66.036</td>\n",
       "      <td>4</td>\n",
       "      <td>['bebop', 'big band', 'cool jazz', 'dixieland'...</td>\n",
       "      <td>52</td>\n",
       "      <td>[]</td>\n",
       "      <td>37</td>\n",
       "      <td>1993-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271702</th>\n",
       "      <td>Sidney Bechet</td>\n",
       "      <td>spotify:artist:1RsmXc1ZqW3WBs9iwxiSwk</td>\n",
       "      <td>Blame It On The Blues - Alternate Take</td>\n",
       "      <td>spotify:album:04hQBJ7YSuNnZ0nbuXNYbY</td>\n",
       "      <td>175893</td>\n",
       "      <td>Jazz Classics</td>\n",
       "      <td>1</td>\n",
       "      <td>spotify:track:26N4Y48EjprAtvlY6yWZTA</td>\n",
       "      <td>0.574</td>\n",
       "      <td>0.606</td>\n",
       "      <td>...</td>\n",
       "      <td>0.948</td>\n",
       "      <td>0.3490</td>\n",
       "      <td>0.965</td>\n",
       "      <td>101.361</td>\n",
       "      <td>4</td>\n",
       "      <td>['bebop', 'big band', 'cool jazz', 'dixieland'...</td>\n",
       "      <td>52</td>\n",
       "      <td>[]</td>\n",
       "      <td>37</td>\n",
       "      <td>1993-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445190</th>\n",
       "      <td>Sidney Bechet</td>\n",
       "      <td>spotify:artist:1RsmXc1ZqW3WBs9iwxiSwk</td>\n",
       "      <td>Summertime</td>\n",
       "      <td>spotify:album:04hQBJ7YSuNnZ0nbuXNYbY</td>\n",
       "      <td>251906</td>\n",
       "      <td>Jazz Classics</td>\n",
       "      <td>16</td>\n",
       "      <td>spotify:track:3RlJx8xwZEyToSuGrygilr</td>\n",
       "      <td>0.608</td>\n",
       "      <td>0.138</td>\n",
       "      <td>...</td>\n",
       "      <td>0.908</td>\n",
       "      <td>0.0853</td>\n",
       "      <td>0.318</td>\n",
       "      <td>83.124</td>\n",
       "      <td>4</td>\n",
       "      <td>['bebop', 'big band', 'cool jazz', 'dixieland'...</td>\n",
       "      <td>52</td>\n",
       "      <td>[]</td>\n",
       "      <td>37</td>\n",
       "      <td>1993-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626275</th>\n",
       "      <td>Sidney Bechet</td>\n",
       "      <td>spotify:artist:1RsmXc1ZqW3WBs9iwxiSwk</td>\n",
       "      <td>Dear Old Southland</td>\n",
       "      <td>spotify:album:04hQBJ7YSuNnZ0nbuXNYbY</td>\n",
       "      <td>243693</td>\n",
       "      <td>Jazz Classics</td>\n",
       "      <td>1</td>\n",
       "      <td>spotify:track:4qwAa1rOm8iaegHzoM1b31</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.320</td>\n",
       "      <td>...</td>\n",
       "      <td>0.842</td>\n",
       "      <td>0.1950</td>\n",
       "      <td>0.613</td>\n",
       "      <td>86.186</td>\n",
       "      <td>4</td>\n",
       "      <td>['bebop', 'big band', 'cool jazz', 'dixieland'...</td>\n",
       "      <td>52</td>\n",
       "      <td>[]</td>\n",
       "      <td>37</td>\n",
       "      <td>1993-01-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               artist_name  \\\n",
       "song_id                                      \n",
       "0        Sidney Bechet's Blue Note Jazzmen   \n",
       "159583                       Sidney Bechet   \n",
       "271702                       Sidney Bechet   \n",
       "445190                       Sidney Bechet   \n",
       "626275                       Sidney Bechet   \n",
       "\n",
       "                                    artist_uri  \\\n",
       "song_id                                          \n",
       "0        spotify:artist:2XouUSO0EAJ9gMMoHiXqMt   \n",
       "159583   spotify:artist:1RsmXc1ZqW3WBs9iwxiSwk   \n",
       "271702   spotify:artist:1RsmXc1ZqW3WBs9iwxiSwk   \n",
       "445190   spotify:artist:1RsmXc1ZqW3WBs9iwxiSwk   \n",
       "626275   spotify:artist:1RsmXc1ZqW3WBs9iwxiSwk   \n",
       "\n",
       "                                     track_name  \\\n",
       "song_id                                           \n",
       "0                                Muskrat Ramble   \n",
       "159583                             Blue Horizon   \n",
       "271702   Blame It On The Blues - Alternate Take   \n",
       "445190                               Summertime   \n",
       "626275                       Dear Old Southland   \n",
       "\n",
       "                                    album_uri  duration_ms     album_name  \\\n",
       "song_id                                                                     \n",
       "0        spotify:album:04hQBJ7YSuNnZ0nbuXNYbY       220293  Jazz Classics   \n",
       "159583   spotify:album:04hQBJ7YSuNnZ0nbuXNYbY       264933  Jazz Classics   \n",
       "271702   spotify:album:04hQBJ7YSuNnZ0nbuXNYbY       175893  Jazz Classics   \n",
       "445190   spotify:album:04hQBJ7YSuNnZ0nbuXNYbY       251906  Jazz Classics   \n",
       "626275   spotify:album:04hQBJ7YSuNnZ0nbuXNYbY       243693  Jazz Classics   \n",
       "\n",
       "         count                             track_uri  danceability  energy  \\\n",
       "song_id                                                                      \n",
       "0            1  spotify:track:0002yNGLtYSYtc0X6ZnFvp         0.455   0.623   \n",
       "159583       5  spotify:track:1EWPMNHfdVNJwBpG9BcxXB         0.327   0.372   \n",
       "271702       1  spotify:track:26N4Y48EjprAtvlY6yWZTA         0.574   0.606   \n",
       "445190      16  spotify:track:3RlJx8xwZEyToSuGrygilr         0.608   0.138   \n",
       "626275       1  spotify:track:4qwAa1rOm8iaegHzoM1b31         0.400   0.320   \n",
       "\n",
       "         ...  instrumentalness  liveness  valence    tempo  time_signature  \\\n",
       "song_id  ...                                                                 \n",
       "0        ...             0.903    0.6340    0.951  182.345               4   \n",
       "159583   ...             0.835    0.1530    0.380   66.036               4   \n",
       "271702   ...             0.948    0.3490    0.965  101.361               4   \n",
       "445190   ...             0.908    0.0853    0.318   83.124               4   \n",
       "626275   ...             0.842    0.1950    0.613   86.186               4   \n",
       "\n",
       "                                             artist_genres  artist_popularity  \\\n",
       "song_id                                                                         \n",
       "0                                                       []                 18   \n",
       "159583   ['bebop', 'big band', 'cool jazz', 'dixieland'...                 52   \n",
       "271702   ['bebop', 'big band', 'cool jazz', 'dixieland'...                 52   \n",
       "445190   ['bebop', 'big band', 'cool jazz', 'dixieland'...                 52   \n",
       "626275   ['bebop', 'big band', 'cool jazz', 'dixieland'...                 52   \n",
       "\n",
       "         album_genres  album_popularity  album_release_date  \n",
       "song_id                                                      \n",
       "0                  []                37          1993-01-01  \n",
       "159583             []                37          1993-01-01  \n",
       "271702             []                37          1993-01-01  \n",
       "445190             []                37          1993-01-01  \n",
       "626275             []                37          1993-01-01  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(master.shape)\n",
    "display(master.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some missing values here (throws an error if we try to fit a model). Drop rows with NA, as the remaining rows are those we intend to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 9 observations\n"
     ]
    }
   ],
   "source": [
    "old = master.shape\n",
    "master.dropna(axis = 0, inplace = True)\n",
    "print('Removed', old[0] - master.shape[0], 'observations')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert `album_release_year` to a continuous number of the release year. The day of month or month itself of the release date is likely much less important. Should ideally treat as categorical, but this would give a *lot* of levels and not unreasonble to treat year as ordinal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "master['album_release_year'] = np.array(\n",
    "    [reldate[0:4] for reldate in master['album_release_date']], dtype = 'int')\n",
    "master.drop(['album_release_date'], 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several columns contain text (should be categorical):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "artist_name            object\n",
       "artist_uri             object\n",
       "track_name             object\n",
       "album_uri              object\n",
       "duration_ms             int64\n",
       "album_name             object\n",
       "count                   int64\n",
       "track_uri              object\n",
       "danceability          float64\n",
       "energy                float64\n",
       "key                     int64\n",
       "loudness              float64\n",
       "mode                    int64\n",
       "speechiness           float64\n",
       "acousticness          float64\n",
       "instrumentalness      float64\n",
       "liveness              float64\n",
       "valence               float64\n",
       "tempo                 float64\n",
       "time_signature          int64\n",
       "artist_genres          object\n",
       "artist_popularity       int64\n",
       "album_genres           object\n",
       "album_popularity        int64\n",
       "album_release_year      int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove columns that we do not need:\n",
    "- `album_genres` is always empty. Seems like a field that used to exist, but no longer does.\n",
    "- `track_uri` is the url to the track. This is unique to each song and cannot be used to model. It is saved in the stored dataframe for reference if we need it later.\n",
    "- `album_uri` for the same reason.\n",
    "- `artist_uri` for the same reason.\n",
    "\n",
    "Until we can effecrtively one-hot encode as categoricals, any remaining predictors of type `object` can be dropped, so that we only have numeric features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "master.drop(labels = ['album_genres', 'track_uri', 'album_uri', 'artist_uri'], \n",
    "           axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Artist genres is missing for about $18\\%$ of songs. For those that have it, it's a list of sometimes extremely specific genres. Hard to do something useful with, so drop it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17600038402265733"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(master.artist_genres == '[]')/master.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also can't do anything interest with track name (unless we want to try to use NLP to look for similarities in titles, but that seems like a stretch, so drop that too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "master.drop(['track_name', 'artist_genres'], 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now whatever column is of type `object` is one we want to treat as categorical and one-hot-encode. Songs in the same album and/or by the same artist likely fit well together.  \n",
    "  \n",
    "**Note:** Perhaps redundant to keep both? If a song is in the same album, most of the time it will also be by the same artist? At the same time, collection albums may be a great way to indirectly capture genre information and relatedness beyond being by the same artist. There's just a *lot* of albums, i.e. we'll get a stupid amount of features with one-hot-encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "artist_name            object\n",
       "duration_ms             int64\n",
       "album_name             object\n",
       "count                   int64\n",
       "danceability          float64\n",
       "energy                float64\n",
       "key                     int64\n",
       "loudness              float64\n",
       "mode                    int64\n",
       "speechiness           float64\n",
       "acousticness          float64\n",
       "instrumentalness      float64\n",
       "liveness              float64\n",
       "valence               float64\n",
       "tempo                 float64\n",
       "time_signature          int64\n",
       "artist_popularity       int64\n",
       "album_popularity        int64\n",
       "album_release_year      int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fancy model alternatives\n",
    "\n",
    "## Multiple Correspondence Analysis (MCA)\n",
    "Not as a model, but as an alternative to PCA that works on categorical (binary) data, either for widened song-in-playlist indicators, or one-hot-encoded `artist` and/or `album` for songs.\n",
    "\n",
    "Read more here: http://vxy10.github.io/2016/06/10/intro-MCA/  \n",
    "Package here: https://pypi.org/project/mca/  \n",
    "Why PCA isn't appropriate: https://www.reddit.com/r/MachineLearning/comments/3nuh7g/is_it_effective_to_use_one_hot_encoding_of/\n",
    "\n",
    "Options:\n",
    "1. ~~MCA to reduce dimensionality of song-in-playlist indicators (array takes too much memory and spares doesn't seem to work)~~: even with sparse and $n>100$ this runs OOM. See notebook `sparse matrix with MCA -- OOM error.ipynb` for the various attempts. \n",
    "2. MCA to reduce dimensionality of one-hot-encoded `artist` and/or `album` indicators\n",
    "\n",
    "## Cosine Similarity and/or Euclidean Distance\n",
    "Computes the angle $[0, 1]$ between two vectors, in our case between the vector of playlist indicators of two songs. A similarity of 1 means the songs appear in the exact same playlists.\n",
    "\n",
    "Note that similarity is 1 - distance, and vice versa.\n",
    "\n",
    "Can be done in chunks or subsets, but is still *very* computationally expensive due to the size of the vectors and sheer number of songs.\n",
    "\n",
    "**Update:** Is now very fast using sparse `scipy` matrices and `sklearn` distance algorithms. Still runs OOM if try to do it pairwise across entire dataset, but not really any need for that: better to do one-vs-all (across entire dataset or across K-Means cluster) when populating playlists with seed songs. See details below.\n",
    "\n",
    "## Multi-label models\n",
    "From sklearn documentation: **Multiclass** classification algorithms require that each observation belongs to one â€“ and only one, though potentially among many possible â€“ class. **Multilabel**, in contrast, assigns to each sample a *set* of target labels. This can be thought as predicting properties of a data-point that are not mutually exclusive, such as topics that are relevant for a document. A text might be about any of religion, politics, finance or education at the same time or none of these.\n",
    "\n",
    "Read more here: https://scikit-learn.org/stable/modules/multiclass.html  \n",
    "Multi-label models in `sklearn` on text data: https://towardsdatascience.com/multi-label-text-classification-with-scikit-learn-30714b7819c5\n",
    "\n",
    "1. Treat playlists as labels and assign each song multiple, according to which playlists it's in. Challenge: 200,000 classes, many with very few observations\n",
    "\n",
    "## HDBSCAN: big-boy clustering\n",
    "Alternative to K-Means.\n",
    "\n",
    "Docs: https://hdbscan.readthedocs.io/en/latest/  \n",
    "How HDBSCAN works: https://hdbscan.readthedocs.io/en/latest/how_hdbscan_works.html  \n",
    "Lightning Talk, Clustering with HDBScan: https://towardsdatascience.com/lightning-talk-clustering-with-hdbscan-d47b83d1b03a\n",
    "\n",
    "## Matrix decomposition\n",
    "`sklearn` has a great library for matrix decomposition, including on sparse matrices: https://scikit-learn.org/stable/modules/decomposition.html\n",
    "\n",
    "https://scikit-learn.org/stable/modules/classes.html#module-sklearn.decomposition\n",
    "\n",
    "Options to look into which is appropriate, depending on whether on just songs-in-playlist indicators, one-hot-encoded categoricals (artist, album, etc.), and/or the continuous data:\n",
    "- Truncated Singular Value Decomposition\n",
    "- Latent Dirichlet Allocation\n",
    "- Mini-batch sparse PCA (looks like we can get PCA to run on everything after all)\n",
    "- Kernel PCA\n",
    "\n",
    "## Embedding\n",
    "*\"Formally, an embedding is a mapping of a categorical variable into an n-dimensional vector.\n",
    "This provides us with 2 advantages. First, we limit the number of columns we need per category. Second, embeddings by nature intrinsically group similar variables together.\"*\n",
    "\n",
    "*\"Traditionally, the best way to deal with categorical data has been one hot encoding â€” a method where the categorical variable is broken into as many features as the unique number of categories for that feature and for every row, a 1 is assigned for the feature representing that rowâ€™s category and rest of the features are marked 0.\n",
    "There are a lot of issues with this method. For categories with lots of unique features we get a lot of sparse data. Also each vector is equidistant from every other vector which causes us to lose the value of relationships between variables.\n",
    "Embeddings are a solution to dealing with categorical variables while avoiding a lot of the pitfalls of one hot encoding.\"*\n",
    "\n",
    "https://medium.com/@davidheffernan_99410/an-introduction-to-using-categorical-embeddings-ee686ed7e7f9\n",
    "\n",
    "https://towardsdatascience.com/building-a-recommendation-system-using-neural-network-embeddings-1ef92e5c80c9\n",
    "\n",
    "Options\n",
    "- Can be used on text as a supervised problem\n",
    "- Unclear how it would work on songs-in-playlists indicators: nothing to make it supervised against?\n",
    "\n",
    "## ~~Normalised Mutual Information~~~\n",
    "Score to evaluate unsupervised clustering: https://www.analyticsvidhya.com/blog/2018/05/essentials-of-deep-learning-trudging-into-unsupervised-deep-learning/\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.normalized_mutual_info_score.html\n",
    "\n",
    "NMI only works with known labels; compares clusters to labels, which we don't have.\n",
    "\n",
    "## Auto-Encoder into K-Means (or other)\n",
    "https://www.analyticsvidhya.com/blog/2018/05/essentials-of-deep-learning-trudging-into-unsupervised-deep-learning/  \n",
    "Many clustering algorithms, K-Means included, struggle on high-dimensional data. Use an auto-encoder to reduce dimensionality first, then run K-means on the predictions of that autoencoder (i.e. lower-dimensional data).\n",
    "\n",
    "How does it handle extremely sparse indicators?\n",
    "\n",
    "## Deep Embedding for Clustering Analysis (DEC)\n",
    "https://www.analyticsvidhya.com/blog/2018/05/essentials-of-deep-learning-trudging-into-unsupervised-deep-learning/\n",
    "\n",
    "https://arxiv.org/abs/1511.06335  \n",
    "  \n",
    "State of the art model related to the above. Trains both clustering and autoencoder models to get better performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Song-in-playlist indicators as sparse matrix\n",
    "https://pandas.pydata.org/pandas-docs/stable/user_guide/sparse.html#sparse-migration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "284_0      [340039, 125250, 881533, 653897, 49614, 356319...\n",
       "284_1      [738782, 7646, 142078, 900881, 533258, 429837,...\n",
       "284_2      [552361, 135177, 507876, 865927, 638474, 55164...\n",
       "284_3      [214695, 27387, 700562, 448130, 1000188, 37723...\n",
       "284_4      [576080, 600, 170841, 842370, 450149, 8624, 89...\n",
       "                                 ...                        \n",
       "283_995    [387321, 550498, 904203, 123847, 811636, 17392...\n",
       "283_996    [744373, 636897, 939642, 839829, 731677, 88964...\n",
       "283_997    [16947, 679919, 17738, 263393, 313648, 66922, ...\n",
       "283_998    [615912, 323911, 855546, 150903, 539581, 18282...\n",
       "283_999    [985680, 723192, 786619, 812661, 423261, 14162...\n",
       "Length: 200000, dtype: object"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "playlists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read list of lists: parent index is playlist ID, child index is song in that playlist\n",
    "playlists = pd.read_pickle('../data/playlists_song_ids_200.pkl')\n",
    "\n",
    "# Give each parent list a number, i.e. playlist ID\n",
    "play, song = zip(*enumerate(playlists))\n",
    "\n",
    "# Expand into pairs of playlist-song, i.e. 100-long playlist becomes 100 pairs\n",
    "pairs = [[z[0], s] for z in zip(play, song) for s in z[1]]\n",
    "\n",
    "# column is song ID, row is playlist ID\n",
    "col, row = zip(*pairs)\n",
    "assert len(row) == len(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1003760, 200000)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create sparse matrix\n",
    "from scipy.sparse import csr_matrix, coo_matrix\n",
    "mat = csr_matrix((np.ones(len(col), dtype = 'int'), (row, col)))\n",
    "mat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Warning:** Usually `mat.A` gets you a dense matrix with zeros as zeros instead of simply being left out, *but* that will make Jupyter shit the bed due to the crazy memory requirements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Various songs were ditched from the master songs table when adding metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mat = mat[master.index.values, :]\n",
    "assert mat.shape[0] == master.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like it works: first playlist has 13 stored elements, corresponding to `len(playlists[0])`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, <999941x1 sparse matrix of type '<class 'numpy.int64'>'\n",
       " \twith 13 stored elements in Compressed Sparse Row format>)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(playlists[0]), mat[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Try Numpy operations on sparse matrix to see if we can do anything useful with it\n",
    "**Works like a charm, and is *very* fast! :D**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1],\n",
       "        [5],\n",
       "        [1],\n",
       "        ...,\n",
       "        [1],\n",
       "        [1],\n",
       "        [1]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Occurrences of each song across all playlists\n",
    "np.sum(mat, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 13,  85, 156, ...,  48,   8,  25]], dtype=int64)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Songs in each playlist\n",
    "np.sum(mat, axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop songs that occur below a certain threshold $n$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs_keep_ind = np.argwhere(np.sum(mat, axis = 1) >= n)[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(123328, 200000)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_sub = mat[songs_keep_ind, :]\n",
    "mat_sub.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999346299381664"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sparsity original\n",
    "1 - (np.sum(mat)/(mat.shape[0]*mat.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9995422149876751"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sparsity new subset\n",
    "1 - (np.sum(mat_sub)/(mat_sub.shape[0]*mat_sub.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop the same songs from the master songs metadata table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(123328, 19)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_sub = master.iloc[songs_keep_ind, :]\n",
    "master_sub.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some playlists now have no songs or are very short. Drop those containing less than $m$ songs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_sums = np.array(np.sum(mat_sub, axis = 0)).reshape((-1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(123328, 183939)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_sub = mat_sub[:, p_sums >= m]\n",
    "mat_sub.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Warning:** Some songs may now never appear in any playlist (happens at least once), so be aware that summing across columns will yield some NaNs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E.g. we have "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, <1x183939 sparse matrix of type '<class 'numpy.int64'>'\n",
       " \twith 12 stored elements in Compressed Sparse Row format>)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(mat_sub[0, :].A), mat_sub[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine, euclidean, cdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cosine here is DISTANCE, not similarity\n",
    "1 - cosine(mat_sub[0, :].A, mat_sub[1, :].A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - cosine(mat_sub[0, :].A, mat_sub[0, :].A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing cosine similarity of even one song across the entire dataset is extremely slow. Probably best to do this from within the relevant cluster when pulling new songs to populate playlist (but need a lot of clusters for this to pay off, since time becomes original time divided by number of clusters)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ~~TODO: find a faster way to calculate this~~\n",
    "#### DONE, see below\n",
    "\n",
    "**Note:** The method is slow, but we'd technically only have to do this once per cluster (in total the entire dataset once) if we combine all seed songs into one vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarities = [1 - cosine(mat_sub[0, :].A, mat_sub[i, :].A) for i in range(mat_sub.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace NaN with 0: occurs if a song never appears in any remaining playlist\n",
    "similarities = np.nan_to_num(similarities, nan = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(similarities) == mat_sub.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Song ID of first song (for which we want to find closest neighbours):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "445190"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_sub.index.values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO: find a good way combine all seed songs into one vector and calculate cosine similarity against all songs in cluster from which we pull new songs for efficiency, preferably weighting shared playlists across the seed songs more heavily (if multiple seed songs are in a playlist, that's likely a good playlist to pull new songs from)\n",
    "Way to weight more important songs: e.g. if $n$ songs appear in the most frequent playlist, weight that by $1$ and all playlists with only one seed song by $1/n$ when calculating distance. Hence, a song that appears in the most frequent playlist gets a distance of $0$ for that playlist, $1$ for playlists that aren't a match, and $1-1/n$ for playlists with only one seed song."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.2236068 , 0.20412415, 0.19867985, 0.19364917,\n",
       "       0.19245009, 0.18257419, 0.16012815, 0.15430335, 0.1490712 ])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the ten songs most similar to the first song in master (including self)\n",
    "similarities[np.argsort(similarities)[::-1][0:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([445190, 421694, 883140, 135113, 800583, 657505, 717728, 644240,\n",
       "       820522, 842045])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Song IDs of the closest songs\n",
    "master_sub.index.values[np.argsort(similarities)[::-1][0:10]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ~~TODO: Maybe Euclidian distance is faster and/or makes more sense?  ~~~\n",
    "#### Not faster, boils down to judgment call which makes more sense. See below.\n",
    "That's what the paper use in their probabilistic embedding of playlists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "euc_dist = [euclidean(mat_sub[0, :].A, mat_sub[i, :].A) for i in range(mat_sub.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 3.46410162, 3.60555128, 3.60555128, 3.60555128,\n",
       "       3.74165739, 3.74165739, 3.74165739, 3.74165739, 3.87298335])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Euclidean distances of 10 closest songs in indicator vector space\n",
    "np.array(euc_dist)[np.argsort(euc_dist)][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([445190, 348315, 231929, 613065, 355371, 538055, 202803, 513149,\n",
       "       242376,   1975])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_sub.index.values[np.argsort(euc_dist)[0:10]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cosine similarity and Euclidean distance give different results. Which is better?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is super-efficient! Runs in virtually an instant\n",
    "**Note:** it is not the most precise way of doing the computation, trading off precision for speed, but it is so very nearly identical as to be negligibly imprecise.\n",
    "\n",
    "**Note:** Still shits the bed if try to do it for the entire dataset. Need to do one or a few vs all.\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.euclidean_distances.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import euclidean_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "euc_dist_sklearn = euclidean_distances(mat_sub, mat_sub[0, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "euc_dist_sklearn = euc_dist_sklearn.reshape((-1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Exactly equal to scipy in % of cases:', \n",
    "      100*np.sum(euc_dist == euc_dist_sklearn)/len(euc_dist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 3.46410162, 3.60555128, 3.60555128, 3.60555128,\n",
       "       3.74165739, 3.74165739, 3.74165739, 3.74165739, 3.87298335])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sorted closest songs by distance\n",
    "euc_dist_sklearn[np.argsort(euc_dist_sklearn)][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([445190, 348315, 231929, 613065, 355371, 538055, 202803, 513149,\n",
       "       242376,   1975])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sorted closet songs by ID\n",
    "master_sub.index.values[np.argsort(euc_dist_sklearn)[0:10]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Try same speed-up for cosine distance / similarity\n",
    "Also very fast\n",
    "  \n",
    "*\"Cosine distance is defined as 1.0 minus the cosine similarity.\"*  \n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.cosine_distances.html#sklearn.metrics.pairwise.cosine_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_dist_sklearn = cosine_distances(mat_sub, mat_sub[0, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_dist_sklearn = cos_dist_sklearn.reshape((-1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.7763932 , 0.79587585, 0.80132015, 0.80635083,\n",
       "       0.80754991, 0.81742581, 0.83987185, 0.84569665, 0.8509288 ])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sorted closest songs by cosine distance\n",
    "cos_dist_sklearn[np.argsort(cos_dist_sklearn)][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([445190, 421694, 883140, 135113, 800583, 657505, 717728, 644240,\n",
       "       820522, 842045])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sorted closest songs by cosine distance\n",
    "master_sub.index.values[np.argsort(cos_dist_sklearn)[0:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist_name</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>album_name</th>\n",
       "      <th>count</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>artist_popularity</th>\n",
       "      <th>album_popularity</th>\n",
       "      <th>album_release_year</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>song_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>445190</th>\n",
       "      <td>Sidney Bechet</td>\n",
       "      <td>251906</td>\n",
       "      <td>Jazz Classics</td>\n",
       "      <td>16</td>\n",
       "      <td>0.608</td>\n",
       "      <td>0.1380</td>\n",
       "      <td>3</td>\n",
       "      <td>-17.379</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0409</td>\n",
       "      <td>0.979</td>\n",
       "      <td>0.90800</td>\n",
       "      <td>0.0853</td>\n",
       "      <td>0.318</td>\n",
       "      <td>83.124</td>\n",
       "      <td>4</td>\n",
       "      <td>52</td>\n",
       "      <td>37</td>\n",
       "      <td>1993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421694</th>\n",
       "      <td>Kenny Dorham</td>\n",
       "      <td>190400</td>\n",
       "      <td>Quiet Kenny</td>\n",
       "      <td>15</td>\n",
       "      <td>0.336</td>\n",
       "      <td>0.0619</td>\n",
       "      <td>5</td>\n",
       "      <td>-20.494</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0363</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.89100</td>\n",
       "      <td>0.1100</td>\n",
       "      <td>0.197</td>\n",
       "      <td>60.705</td>\n",
       "      <td>4</td>\n",
       "      <td>44</td>\n",
       "      <td>41</td>\n",
       "      <td>1992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883140</th>\n",
       "      <td>Joe Henderson</td>\n",
       "      <td>482440</td>\n",
       "      <td>Page One</td>\n",
       "      <td>13</td>\n",
       "      <td>0.531</td>\n",
       "      <td>0.3660</td>\n",
       "      <td>5</td>\n",
       "      <td>-11.697</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0496</td>\n",
       "      <td>0.911</td>\n",
       "      <td>0.88000</td>\n",
       "      <td>0.0916</td>\n",
       "      <td>0.785</td>\n",
       "      <td>81.867</td>\n",
       "      <td>4</td>\n",
       "      <td>46</td>\n",
       "      <td>39</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135113</th>\n",
       "      <td>Chet Baker</td>\n",
       "      <td>318466</td>\n",
       "      <td>Chet</td>\n",
       "      <td>19</td>\n",
       "      <td>0.505</td>\n",
       "      <td>0.0251</td>\n",
       "      <td>3</td>\n",
       "      <td>-21.220</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0393</td>\n",
       "      <td>0.941</td>\n",
       "      <td>0.90600</td>\n",
       "      <td>0.1420</td>\n",
       "      <td>0.175</td>\n",
       "      <td>113.162</td>\n",
       "      <td>4</td>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>1959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800583</th>\n",
       "      <td>Chet Baker</td>\n",
       "      <td>413786</td>\n",
       "      <td>Chet [Keepnews Collection]</td>\n",
       "      <td>21</td>\n",
       "      <td>0.441</td>\n",
       "      <td>0.0319</td>\n",
       "      <td>2</td>\n",
       "      <td>-19.168</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0357</td>\n",
       "      <td>0.872</td>\n",
       "      <td>0.89800</td>\n",
       "      <td>0.0880</td>\n",
       "      <td>0.113</td>\n",
       "      <td>110.471</td>\n",
       "      <td>4</td>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>1959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>657505</th>\n",
       "      <td>Oliver Nelson</td>\n",
       "      <td>526826</td>\n",
       "      <td>The Blues And The Abstract Truth</td>\n",
       "      <td>41</td>\n",
       "      <td>0.536</td>\n",
       "      <td>0.2490</td>\n",
       "      <td>0</td>\n",
       "      <td>-14.381</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0431</td>\n",
       "      <td>0.884</td>\n",
       "      <td>0.85400</td>\n",
       "      <td>0.1230</td>\n",
       "      <td>0.350</td>\n",
       "      <td>116.289</td>\n",
       "      <td>4</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>1961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717728</th>\n",
       "      <td>Herb Ellis</td>\n",
       "      <td>251600</td>\n",
       "      <td>Ellis In Wonderland</td>\n",
       "      <td>10</td>\n",
       "      <td>0.798</td>\n",
       "      <td>0.2120</td>\n",
       "      <td>0</td>\n",
       "      <td>-10.529</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0436</td>\n",
       "      <td>0.933</td>\n",
       "      <td>0.95000</td>\n",
       "      <td>0.1020</td>\n",
       "      <td>0.592</td>\n",
       "      <td>118.149</td>\n",
       "      <td>4</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>1956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644240</th>\n",
       "      <td>J.J. Johnson</td>\n",
       "      <td>548240</td>\n",
       "      <td>The Trombone Master</td>\n",
       "      <td>16</td>\n",
       "      <td>0.466</td>\n",
       "      <td>0.3950</td>\n",
       "      <td>5</td>\n",
       "      <td>-18.022</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0432</td>\n",
       "      <td>0.442</td>\n",
       "      <td>0.00531</td>\n",
       "      <td>0.2780</td>\n",
       "      <td>0.664</td>\n",
       "      <td>118.500</td>\n",
       "      <td>4</td>\n",
       "      <td>37</td>\n",
       "      <td>28</td>\n",
       "      <td>1989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>820522</th>\n",
       "      <td>Lee Morgan</td>\n",
       "      <td>339333</td>\n",
       "      <td>Candy</td>\n",
       "      <td>16</td>\n",
       "      <td>0.416</td>\n",
       "      <td>0.2010</td>\n",
       "      <td>8</td>\n",
       "      <td>-11.461</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0379</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.80300</td>\n",
       "      <td>0.1070</td>\n",
       "      <td>0.372</td>\n",
       "      <td>165.869</td>\n",
       "      <td>3</td>\n",
       "      <td>51</td>\n",
       "      <td>36</td>\n",
       "      <td>1957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842045</th>\n",
       "      <td>Gerry Mulligan</td>\n",
       "      <td>442506</td>\n",
       "      <td>Gerry Mulligan Meets Ben Webster</td>\n",
       "      <td>15</td>\n",
       "      <td>0.514</td>\n",
       "      <td>0.0141</td>\n",
       "      <td>1</td>\n",
       "      <td>-24.166</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0448</td>\n",
       "      <td>0.958</td>\n",
       "      <td>0.45800</td>\n",
       "      <td>0.1110</td>\n",
       "      <td>0.112</td>\n",
       "      <td>111.552</td>\n",
       "      <td>4</td>\n",
       "      <td>52</td>\n",
       "      <td>25</td>\n",
       "      <td>1963</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            artist_name  duration_ms                        album_name  count  \\\n",
       "song_id                                                                         \n",
       "445190    Sidney Bechet       251906                     Jazz Classics     16   \n",
       "421694     Kenny Dorham       190400                       Quiet Kenny     15   \n",
       "883140    Joe Henderson       482440                          Page One     13   \n",
       "135113       Chet Baker       318466                              Chet     19   \n",
       "800583       Chet Baker       413786        Chet [Keepnews Collection]     21   \n",
       "657505    Oliver Nelson       526826  The Blues And The Abstract Truth     41   \n",
       "717728       Herb Ellis       251600               Ellis In Wonderland     10   \n",
       "644240     J.J. Johnson       548240               The Trombone Master     16   \n",
       "820522       Lee Morgan       339333                             Candy     16   \n",
       "842045   Gerry Mulligan       442506  Gerry Mulligan Meets Ben Webster     15   \n",
       "\n",
       "         danceability  energy  key  loudness  mode  speechiness  acousticness  \\\n",
       "song_id                                                                         \n",
       "445190          0.608  0.1380    3   -17.379     1       0.0409         0.979   \n",
       "421694          0.336  0.0619    5   -20.494     0       0.0363         0.985   \n",
       "883140          0.531  0.3660    5   -11.697     0       0.0496         0.911   \n",
       "135113          0.505  0.0251    3   -21.220     1       0.0393         0.941   \n",
       "800583          0.441  0.0319    2   -19.168     0       0.0357         0.872   \n",
       "657505          0.536  0.2490    0   -14.381     0       0.0431         0.884   \n",
       "717728          0.798  0.2120    0   -10.529     1       0.0436         0.933   \n",
       "644240          0.466  0.3950    5   -18.022     0       0.0432         0.442   \n",
       "820522          0.416  0.2010    8   -11.461     1       0.0379         0.975   \n",
       "842045          0.514  0.0141    1   -24.166     1       0.0448         0.958   \n",
       "\n",
       "         instrumentalness  liveness  valence    tempo  time_signature  \\\n",
       "song_id                                                                 \n",
       "445190            0.90800    0.0853    0.318   83.124               4   \n",
       "421694            0.89100    0.1100    0.197   60.705               4   \n",
       "883140            0.88000    0.0916    0.785   81.867               4   \n",
       "135113            0.90600    0.1420    0.175  113.162               4   \n",
       "800583            0.89800    0.0880    0.113  110.471               4   \n",
       "657505            0.85400    0.1230    0.350  116.289               4   \n",
       "717728            0.95000    0.1020    0.592  118.149               4   \n",
       "644240            0.00531    0.2780    0.664  118.500               4   \n",
       "820522            0.80300    0.1070    0.372  165.869               3   \n",
       "842045            0.45800    0.1110    0.112  111.552               4   \n",
       "\n",
       "         artist_popularity  album_popularity  album_release_year  \n",
       "song_id                                                           \n",
       "445190                  52                37                1993  \n",
       "421694                  44                41                1992  \n",
       "883140                  46                39                1999  \n",
       "135113                  68                 1                1959  \n",
       "800583                  68                 1                1959  \n",
       "657505                  43                 0                1961  \n",
       "717728                  51                 0                1956  \n",
       "644240                  37                28                1989  \n",
       "820522                  51                36                1957  \n",
       "842045                  52                25                1963  "
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_sub.loc[master_sub.index.values[np.argsort(cos_dist_sklearn)[0:10]]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Truncated SVD\n",
    "https://scikit-learn.org/stable/modules/decomposition.html#lsa  \n",
    "*\"TruncatedSVD is very similar to PCA, but differs in that it works on sample matrices  directly instead of their covariance matrices. When the columnwise (per-feature) means of  are subtracted from the feature values, truncated SVD on the resulting matrix is equivalent to PCA. In practical terms, this means that the TruncatedSVD transformer accepts scipy.sparse matrices without the need to densify them, as densifying may fill up memory even for medium-sized document collections.\"*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsvd = TruncatedSVD(n_components = 100, n_iter = 10, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TruncatedSVD(algorithm='randomized', n_components=100, n_iter=10,\n",
       "             random_state=42, tol=0.0)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsvd.fit(mat_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01383844, 0.00809865, 0.00609205, 0.0057266 , 0.00520378,\n",
       "       0.00450739, 0.00359385, 0.00280834, 0.00265275, 0.00251792,\n",
       "       0.00230597, 0.00213145, 0.00207328, 0.00198966, 0.00192167,\n",
       "       0.00186485, 0.00181185, 0.00170267, 0.00169155, 0.00155155,\n",
       "       0.00149177, 0.00140797, 0.00137596, 0.00134795, 0.0013379 ,\n",
       "       0.00127013, 0.00124342, 0.0011895 , 0.00117219, 0.00115459,\n",
       "       0.00113761, 0.00109757, 0.00106658, 0.00101405, 0.00101133,\n",
       "       0.00100415, 0.00095823, 0.00095001, 0.000926  , 0.00091934,\n",
       "       0.00088557, 0.00085431, 0.00084836, 0.00083353, 0.00081405,\n",
       "       0.00080045, 0.0007799 , 0.00076834, 0.00075532, 0.00074718,\n",
       "       0.00071362, 0.0007062 , 0.00070509, 0.00070138, 0.00069256,\n",
       "       0.00066742, 0.00066651, 0.0006448 , 0.00063775, 0.00063527,\n",
       "       0.00062548, 0.00061817, 0.00061363, 0.00060879, 0.00060188,\n",
       "       0.00059092, 0.00058793, 0.0005846 , 0.00057103, 0.00057008,\n",
       "       0.00056493, 0.0005547 , 0.00055175, 0.00055225, 0.00054433,\n",
       "       0.00054262, 0.00053696, 0.00053252, 0.00052937, 0.00052577,\n",
       "       0.00052294, 0.00051607, 0.00051154, 0.00050526, 0.00050269,\n",
       "       0.00049885, 0.0004945 , 0.00048507, 0.00048199, 0.00048041,\n",
       "       0.00047606, 0.00047234, 0.00047058, 0.00046402, 0.00046267,\n",
       "       0.00045919, 0.00045588, 0.00044696, 0.00044419, 0.00044207])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsvd.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01383844, 0.02193709, 0.02802914, 0.03375574, 0.03895952,\n",
       "       0.04346691, 0.04706076, 0.0498691 , 0.05252185, 0.05503977,\n",
       "       0.05734574, 0.05947719, 0.06155047, 0.06354013, 0.0654618 ,\n",
       "       0.06732665, 0.06913851, 0.07084117, 0.07253272, 0.07408427,\n",
       "       0.07557604, 0.076984  , 0.07835996, 0.07970791, 0.08104582,\n",
       "       0.08231595, 0.08355936, 0.08474887, 0.08592106, 0.08707565,\n",
       "       0.08821326, 0.08931083, 0.09037741, 0.09139145, 0.09240279,\n",
       "       0.09340694, 0.09436517, 0.09531517, 0.09624118, 0.09716052,\n",
       "       0.09804609, 0.09890041, 0.09974876, 0.10058229, 0.10139634,\n",
       "       0.10219679, 0.10297669, 0.10374503, 0.10450035, 0.10524753,\n",
       "       0.10596115, 0.10666735, 0.10737244, 0.10807382, 0.10876638,\n",
       "       0.1094338 , 0.11010031, 0.11074511, 0.11138286, 0.11201812,\n",
       "       0.1126436 , 0.11326177, 0.1138754 , 0.11448418, 0.11508606,\n",
       "       0.11567699, 0.11626491, 0.11684952, 0.11742055, 0.11799063,\n",
       "       0.11855556, 0.11911027, 0.11966202, 0.12021426, 0.12075859,\n",
       "       0.12130121, 0.12183817, 0.12237069, 0.12290005, 0.12342582,\n",
       "       0.12394876, 0.12446483, 0.12497637, 0.12548163, 0.12598433,\n",
       "       0.12648318, 0.12697768, 0.12746275, 0.12794474, 0.12842516,\n",
       "       0.12890122, 0.12937355, 0.12984413, 0.13030815, 0.13077082,\n",
       "       0.13123   , 0.13168589, 0.13213285, 0.13257703, 0.1330191 ])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.cumsum(tsvd.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "100 singular values only account for a total of 13% of the variation. Likely because of the extreme sparsity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: MCA one-hot-encoded artist and album names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "artist_name            object\n",
       "duration_ms             int64\n",
       "album_name             object\n",
       "count                   int64\n",
       "danceability          float64\n",
       "energy                float64\n",
       "key                     int64\n",
       "loudness              float64\n",
       "mode                    int64\n",
       "speechiness           float64\n",
       "acousticness          float64\n",
       "instrumentalness      float64\n",
       "liveness              float64\n",
       "valence               float64\n",
       "tempo                 float64\n",
       "time_signature          int64\n",
       "artist_popularity       int64\n",
       "album_popularity        int64\n",
       "album_release_year      int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_sub.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert type object to categorical and one-hot-encode with pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Autoencoder into K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Embedding song-in-playlist indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
